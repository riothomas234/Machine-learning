{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 4947,
     "status": "ok",
     "timestamp": 1762462759286,
     "user": {
      "displayName": "Rio Thomas",
      "userId": "08413815757860660345"
     },
     "user_tz": 0
    },
    "id": "lxXe67A94iNZ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 124,
     "status": "ok",
     "timestamp": 1762462760287,
     "user": {
      "displayName": "Rio Thomas",
      "userId": "08413815757860660345"
     },
     "user_tz": 0
    },
    "id": "CPQpBK4-8AU0",
    "outputId": "0fd64905-82ed-40c0-8108-2c3142a2ff42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
     ]
    }
   ],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()\n",
    "\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1199,
     "status": "ok",
     "timestamp": 1762462993791,
     "user": {
      "displayName": "Rio Thomas",
      "userId": "08413815757860660345"
     },
     "user_tz": 0
    },
    "id": "WSAsd71a81es",
    "outputId": "ccdcf916-d666-420e-c765-7eea93c15b92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182597, 3]) torch.Size([182597])\n",
      "torch.Size([22868, 3]) torch.Size([22868])\n",
      "torch.Size([22681, 3]) torch.Size([22681])\n",
      "tensor([[ 0,  0,  0],\n",
      "        [ 0,  0, 11],\n",
      "        [ 0, 11,  5],\n",
      "        [11,  5, 14],\n",
      "        [ 5, 14, 26]])\n"
     ]
    }
   ],
   "source": [
    "block_size = 3\n",
    "\n",
    "def build_dataset(words):\n",
    "\n",
    "  X, Y = [], []\n",
    "  for w in words:\n",
    "    #print(w)\n",
    "    context = [0]* block_size\n",
    "\n",
    "    for ch in w + '.':\n",
    "      ix = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      #print(''.join(itos[i] for i in context),'--->', itos[ix])\n",
    "      context = context[1:]+[ix]\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "\n",
    "\n",
    "import random\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "\n",
    "Xtr, Ytr = build_dataset(words[:n1])\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])\n",
    "Xte, Yte = build_dataset(words[n2:])\n",
    "\n",
    "print(Xtr[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmp(s, dt, t):\n",
    "  ex = torch.all(dt == t.grad).item()\n",
    "  app = torch.allclose(dt, t.grad)\n",
    "  maxdiff = (dt - t.grad).abs().max().item()\n",
    "  print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "qLRXsytd_JQI"
   },
   "outputs": [],
   "source": [
    "#building MLP\n",
    "n_embd = 10 #dimensionality of character embedding vectors\n",
    "n_hidden = 200 #no. of neurons in hidden layer of MLP\n",
    "\n",
    "C = torch.rand((vocab_size,n_embd))\n",
    "W1 = torch.randn((n_embd*block_size,n_hidden)) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden) * 0.01  #b1 redundant because of batchnormalisation bias\n",
    "W2 = torch.randn((n_hidden,vocab_size)) *0.1\n",
    "b2 = torch.randn(vocab_size) * 0.1\n",
    "\n",
    "\n",
    "bngain = torch.randn((1, n_hidden))*0.1+1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1  #non-zero to unmask errors in calculating gradients w.r.t biases.\n",
    "\n",
    "#bnmean_running = torch.zeros((1, n_hidden))\n",
    "#bngain_running = torch.ones((1, n_hidden))\n",
    "\n",
    "parameters = [C, W1 , W2, b2, bngain, bnbias]\n",
    "\n",
    "\n",
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1762464201068,
     "user": {
      "displayName": "Rio Thomas",
      "userId": "08413815757860660345"
     },
     "user_tz": 0
    },
    "id": "M3YnF-x8C_KT"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n = batch_size\n",
    "ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
    "Xb, Yb = Xtr[ix], Ytr[ix]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.8917, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#minibatch construct\n",
    "ix = torch.randint(0,Xtr.shape[0],(batch_size,))\n",
    "\n",
    "Xb, Yb = Xtr[ix], Ytr[ix]\n",
    "\n",
    "emb = C[Xb]\n",
    "embcat = emb.view(emb.shape[0], -1)\n",
    "\n",
    "#Linear Layer 1\n",
    "hprebn = embcat @ W1 + b1\n",
    "\n",
    "#batchnorm layer\n",
    "bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "\n",
    "bndiff = hprebn - bnmeani\n",
    "bndiff2 = bndiff**2\n",
    "bnvar = 1/(n-1)*(bndiff2).sum(0,keepdim=True)\n",
    "bnvar_inv = (bnvar+1e-5)**-0.5\n",
    "bnraw = bndiff * bnvar_inv\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "#non_linearity\n",
    "h = torch.tanh(hpreact)\n",
    "#linear layer 2\n",
    "logits = h @ W2 + b2 #output layer , [32,27]\n",
    "#cross entropy loss - subtract max neuron activation in layer from each activation\n",
    "\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "\n",
    "\n",
    "\n",
    "#logit_maxes = logits.max(1, keepdim=True).values #  [32, 1]\n",
    "norm_logits = logits - logit_maxes  # [32,27]\n",
    "#exp each value to remove negatives\n",
    "counts = norm_logits.exp()   # [32,27]\n",
    "counts_sum = counts.sum(1, keepdims=True) # [32,1]\n",
    "counts_sum_inv = counts_sum**-1\n",
    "#convert each value to prob by dividing by sum of activations across one layer of neurons\n",
    "probs = counts * counts_sum_inv\n",
    "#log each value\n",
    "logprobs = probs.log() # [32,27]\n",
    "\n",
    "#range(n) is a list from 1 to 32.  Yb is list of the correct vocab indices for given input context. \n",
    "#we pick out the log prob of each correct output for each of the 32 inputs, add them and find the mean (equivalent to multiplying the raw values and diving by 32)\n",
    "#if correct output indices has high probability assigned to it by neural net, then just the above would give big value close to 0\n",
    "#if probability is low (which is bad we want the probs of correct values to be high), then above method gives very negative value\n",
    "#but backpropagation minimises loss for best results so we take -loss for which lower negative values indicate high confidence.\n",
    "\n",
    "loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "\n",
    "for p in parameters:\n",
    "    p.grad=None\n",
    "\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, # afaik there is no cleaner way\n",
    "          norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
    "         bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
    "         embcat, emb]:\n",
    "  t.retain_grad()\n",
    "\n",
    "loss.backward()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "dlogprobs[range(n), Yb] = -1.0/n\n",
    "dprobs = dlogprobs * 1/probs\n",
    "dcounts_sum_inv = (dprobs * counts).sum(1, keepdim=True)  #if f(x,y,z,l) = xy + zy + ly , del f/del y = x+z+l\n",
    "dcounts = dprobs*counts_sum_inv\n",
    "dcounts_sum = -counts_sum**-2*dcounts_sum_inv\n",
    "dcounts += torch.ones_like(counts)*dcounts_sum\n",
    "dnorm_logits = dcounts*counts\n",
    "dlogits = dnorm_logits.clone()\n",
    "dlogit_maxes =  (-dnorm_logits).sum(1, keepdim=True)\n",
    "dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes\n",
    "dh = W2.sum(1, keepdim=True)\n",
    "\n",
    "cmp('logprobs', dlogprobs, logprobs)\n",
    "cmp('probs', dprobs, probs)\n",
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
    "cmp('counts_sum', dcounts_sum, counts_sum)\n",
    "cmp('counts', dcounts, counts)\n",
    "cmp('norm_logits', dnorm_logits, norm_logits)\n",
    "cmp('logit_maxes', dlogit_maxes, logit_maxes)\n",
    "cmp('logits', dlogits, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOGiGv44S6PgXYdVSQ0kBBJ",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
